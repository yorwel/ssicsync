{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers\n",
    "#!pip install keybert\n",
    "#pip install auto_gptq==0.2.0\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "import ollama\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Anaconda\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# zero-shot learning pipeline, summarization models available on huggingface - https://huggingface.co/models?pipeline_tag=summarization&sort=downloads\n",
    "\n",
    "from transformers import pipeline\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "summarizer_facebook_bart = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\",device=device) # https://huggingface.co/facebook/bart-large-cnn\n",
    "# classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\",device=device))\n",
    "summarizer_philschmid_bart = pipeline(\"summarization\", model=\"philschmid/bart-large-cnn-samsum\",device=device) # https://huggingface.co/philschmid/bart-large-cnn-samsum\n",
    "summarizer_google_pegasus = pipeline(\"summarization\", model=\"google/pegasus-xsum\",device=device) # https://huggingface.co/google/pegasus-xsum\n",
    "summarizer_falconsai = pipeline(\"summarization\", model=\"Falconsai/text_summarization\",device=device) # https://huggingface.co/Falconsai/text_summarization\n",
    "summarizer_distilbart = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\",device=device)\n",
    "# summarizer_google_pegasusL = pipeline(\"summarization\", model=\"google/pegasus-large\",device=device)) # https://huggingface.co/google/pegasus-large\n",
    "# summarizer_sshleifer_distilbart_6_6 = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-6-6\",device=device)) # https://huggingface.co/sshleifer/distilbart-cnn-6-6\n",
    "summarizer_azma_bart = pipeline(\"summarization\", model=\"Azma-AI/bart-large-text-summarizer\",device=device) # https://huggingface.co/Azma-AI/bart-large-text-summarizer\n",
    "\n",
    "list_of_summarizer = [summarizer_facebook_bart,summarizer_falconsai,summarizer_google_pegasus,summarizer_azma_bart,summarizer_distilbart,summarizer_philschmid_bart]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available(): device = 0  \n",
    "else: device = -1  \n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing with llama13B\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import GPTQConfig\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "quantization_config = GPTQConfig(bits=4, disable_exllama=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"TheBloke/WizardLM-1.0-Uncensored-Llama2-13B-GPTQ\",\n",
    "    quantization_config=quantization_config\n",
    ").to('cuda')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TheBloke/WizardLM-1.0-Uncensored-Llama2-13B-GPTQ\")\n",
    "\n",
    "# Create the pipeline\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM summarization model (pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:603: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Group has classified both joint arrangements as joint investment in a foreign operation. The Group is also a 20% (2021: 20%) partner in Park Court Aoyama The Tower, a joint arrangement formed with a third party.\n",
      "[('joint', 0.4634), ('aoyama', 0.3924), ('arrangement', 0.357), ('partner', 0.3238), ('arrangements', 0.3205)]\n"
     ]
    }
   ],
   "source": [
    "description = \"\"\"principal activity is that of a the following items are recognised in OCI: property developer and the place of business is in Singapore. The Group is also a 20% (2021: 20%) partner in Park Court Aoyama The Tower,\n",
    "a joint arrangement formed with a third party, whose principal activity is that of a   differences arising on the translation of monetary items that in substance form part of the Group s net property developer and the place of business is in Japan.\n",
    "The Group has classified both joint arrangements as joint investment in a foreign operation; operations as the joint venture partners control the joint arrangements collectively and the joint arrangements are not structured through separate legal vehicles.\n",
    "   an investment in equity securities designated at fair value through other comprehensive income (FVOCI); (vi) Transactions eliminated on consolidation\n",
    "   a financial liability designated as a hedge of the net investment in a foreign operation to the extent that the hedge is effective; or Intra-group balances and transactions, and any unrealised income or expenses arising from intra-group transactions,\n",
    "   are eliminated in preparing the consolidated financial statements. Unrealised gains arising from   qualifying cash flow hedges to the extent that the hedges are effective. transactions with equity-accounted investee are eliminated against the investment\n",
    "    to the extent of the Group s interest in the investee. Unrealised losses are eliminated in the same way as unrealised gains, but only to the (ii) Foreign operations extent that there is no evidence of impairment. The assets and liabilities of foreign\n",
    "    operations, including goodwill and fair value adjustments arising on acquisition, (vii) Subsidiaries, associates and joint ventures in the separate financial statements are translated to Singapore dollars at exchange rates prevailing at the reporting\n",
    "    date. The income and expenses of foreign operations are translated to Singapore dollars at exchange rates at the dates of the transactions. Investments in subsidiaries, associates and joint ventures are stated in the Company s statement of financial\n",
    "    position at cost less accumulated impairment losses.\n",
    "Foreign currency differences are recognised in OCI. However, if the foreign operation is a non wholly-owned subsidiary, then the relevant proportionate share of the translation difference is allocated to the non-controlling 3.\"\"\"\n",
    "              \n",
    "#Summarize the description\n",
    "summary = summarizer_facebook_bart(description, max_length=150, min_length=30, do_sample=False)\n",
    "print(summary[0]['summary_text'])\n",
    "\n",
    "from keybert import KeyBERT\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "# Extract keywords from the summarized description\n",
    "keywords = kw_model.extract_keywords(summary[0]['summary_text'])\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facebook/bart-large-cnn: The cost of inventories may not be recoverable in full if any inventories are damaged, or if they become obsolete. The estimate of allowance for inventories is based on the age of these inventories.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 153, but your input_length is only 142. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=71)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falconsai/text_summarization: the cost of inventories may not be recoverable in full if any inventories are damaged or if their selling prices have declined . The estimate of allowance for inventories is based on the age of these inventories, prevailing market conditions of the luxury timepieces and related products in the retail industry and historical allowance experience . Management applies judgement in determining the appropriate allowance based upon a detailed technical assessment .\n",
      "google/pegasus-xsum: The following table sets out the allowance for inventories set out in the Management s Discussion and Analysis of Financial Condition and Results of Operations for the six months to 30 June 2014.\n",
      "Azma-AI/bart-large-text-summarizer: Luxury timepieces and luxury accessories are held in inventories. Management estimates the estimated cost of the inventories based on technical assessment and market conditions.\n",
      "sshleifer/distilbart-cnn-12-6:  The cost of inventories may not be recoverable in full if any inventories are damaged, or if they become obsolete . The estimate of allowance for inventories is based on the age of these inventories, prevailing market conditions of the luxury timepieces and related products in the retail industry .\n",
      "philschmid/bart-large-cnn-samsum: The cost of inventories may not be recoverable in full if they are damaged, obsolete or if their selling prices have declined. Management applies judgement in determining the appropriate allowance for inventories.\n"
     ]
    }
   ],
   "source": [
    "#BRC ASIA LIMITED 2022\n",
    "#Principal Activity SSIC Code 24109\n",
    "#MANUFACTURE OF BASIC IRON AND STEEL N.E.C. (INCLUDING SMELTING)\n",
    "\n",
    "# description = \"\"\"principal activities of the Company are the prefabrication of steel reinforcement for use in concrete, \n",
    "# trading of steel reinforcing bars, and manufacturing and sale of wire mesh fences. \n",
    "# The principal activities of the subsidiaries are disclosed in Note 13 to the fi nancial statements. \n",
    "# \"\"\"\n",
    "\n",
    "description = \"\"\"principal activities are in the retail and distribution of luxury timepieces and luxury accessories. The group holds inventories of $,, (: $,,) as at the end of the reporting year. The cost of inventories may not be recoverable in full if any inventories are damaged, or if they become obsolete, or if their selling prices have declined. The estimate of allowance for inventories is based on the age of these inventories, prevailing market conditions of the luxury timepieces and related products in the retail industry and historical allowance experience which require management s judgement. Management applies judgement in determining the appropriate allowance for inventories based upon a detailed technical assessment of inventories concerned including considering the future demand and future selling prices for the products and ageing analysis of inventories. This methodology relies upon assumptions made in determining the appropriate allowance percentages for each category of inventories.\n",
    "\"\"\"\n",
    "\n",
    "#CITY DEVELOPMENTS LIMITED \n",
    "#Principal Activity SSIC Code 68101 REAL ESTATE DEVELOPERS\n",
    "# description = \"\"\"principal activity is that of a the following items are recognised in OCI: property developer and the place of business is in Singapore. The Group is also a 20% (2021: 20%) partner in Park Court Aoyama The Tower,\n",
    "# a joint arrangement formed with a third party, whose principal activity is that of a   differences arising on the translation of monetary items that in substance form part of the Group s net property developer and the place of business is in Japan.\n",
    "# The Group has classified both joint arrangements as joint investment in a foreign operation; operations as the joint venture partners control the joint arrangements collectively and the joint arrangements are not structured through separate legal vehicles.\n",
    "#    an investment in equity securities designated at fair value through other comprehensive income (FVOCI); (vi) Transactions eliminated on consolidation\n",
    "#    a financial liability designated as a hedge of the net investment in a foreign operation to the extent that the hedge is effective; or Intra-group balances and transactions, and any unrealised income or expenses arising from intra-group transactions,\n",
    "#    are eliminated in preparing the consolidated financial statements. Unrealised gains arising from   qualifying cash flow hedges to the extent that the hedges are effective. transactions with equity-accounted investee are eliminated against the investment\n",
    "#     to the extent of the Group s interest in the investee. Unrealised losses are eliminated in the same way as unrealised gains, but only to the (ii) Foreign operations extent that there is no evidence of impairment. The assets and liabilities of foreign\n",
    "#     operations, including goodwill and fair value adjustments arising on acquisition, (vii) Subsidiaries, associates and joint ventures in the separate financial statements are translated to Singapore dollars at exchange rates prevailing at the reporting\n",
    "#     date. The income and expenses of foreign operations are translated to Singapore dollars at exchange rates at the dates of the transactions. Investments in subsidiaries, associates and joint ventures are stated in the Company s statement of financial\n",
    "#     position at cost less accumulated impairment losses.\n",
    "# Foreign currency differences are recognised in OCI. However, if the foreign operation is a non wholly-owned subsidiary, then the relevant proportionate share of the translation difference is allocated to the non-controlling 3.\"\"\"\n",
    "       \n",
    "    \n",
    "for summarizer in list_of_summarizer:\n",
    "        model_name = summarizer.model.name_or_path if hasattr(summarizer, 'model') else summarizer.__name__\n",
    "        summary = summarizer(description, max_length=max(30, int(len(description)/6)), min_length=30, do_sample=False)\n",
    "        print(f\"{model_name}: {summary[0]['summary_text']}\")\n",
    "\n",
    "\n",
    "#philschmid/bart-large-cnn-samsum - perform the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: retail and distribution of luxury timepieces and luxury accessories\n"
     ]
    }
   ],
   "source": [
    "#Q&A model\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "pipe = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepset/roberta-base-squad2\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"deepset/roberta-base-squad2\")\n",
    "\n",
    "context = \"\"\"principal activities are in the retail and distribution of luxury timepieces and luxury accessories. \n",
    "The group holds inventories of $231,624,000 (2022: $211,199,000) as at the end of the reporting year. \n",
    "The cost of inventories may not be recoverable in full if any inventories are damaged, or if they become obsolete,\n",
    " or if their selling prices have declined. The estimate of allowance for inventories is based on the age of these inventories,\n",
    "   prevailing market conditions of the luxury timepieces and related products in the retail industry and historical allowance experience which require management s judgement. \n",
    "   Management applies judgement in determining the appropriate allowance for inventories based upon a detailed technical assessment of inventories concerned including considering the future demand and future selling prices for the products and ageing analysis of inventories. This methodology relies upon assumptions made in determining the appropriate allowance percentages for each category of inventories..\"\"\"\n",
    "\n",
    "question = \"What's the principal activity of the company?\"\n",
    "answer = pipe(question=question, context=context)\n",
    "\n",
    "print(\"Answer:\", answer['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDF Name</th>\n",
       "      <th>Page Number</th>\n",
       "      <th>UEN Number</th>\n",
       "      <th>Notes Page Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABR HOLDINGS LIMITED 2022 (197803023H).pdf</td>\n",
       "      <td>74</td>\n",
       "      <td>197803023H</td>\n",
       "      <td>principal activities of the Company are the ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABUNDANCE INTERNATIONAL LIMITED 2022 (19750157...</td>\n",
       "      <td>56</td>\n",
       "      <td>197501572K</td>\n",
       "      <td>principal activities of the Company are those ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABUNDANTE LIMITED 2023 (197902587H).pdf</td>\n",
       "      <td>48</td>\n",
       "      <td>197902587H</td>\n",
       "      <td>principal activities of the Company are those ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACCRELIST LTD. 2023 (201413466E).pdf</td>\n",
       "      <td>55</td>\n",
       "      <td>201413466E</td>\n",
       "      <td>principal activities of the Company is investm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACESIAN PARTNERS LIMITED 2022 (199505699D).pdf</td>\n",
       "      <td>54</td>\n",
       "      <td>199505699D</td>\n",
       "      <td>principal activities of the Group consist of d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>TELECHOICE INTERNATIONAL LIMITED 2022 (1998020...</td>\n",
       "      <td>129</td>\n",
       "      <td>199802072R</td>\n",
       "      <td>principal activities of the Company during the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>TT INTERNATIONAL LIMITED 2023 (198403771D).pdf</td>\n",
       "      <td>56</td>\n",
       "      <td>198403771D</td>\n",
       "      <td>principal activities of the Company are those ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>UNITED OVERSEAS INSURANCE LIMITED 2022 (197100...</td>\n",
       "      <td>4</td>\n",
       "      <td>197100152R</td>\n",
       "      <td>principal activities are the underwriting 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>VENTURE CORPORATION LIMITED 2022 (198402886H).pdf</td>\n",
       "      <td>107</td>\n",
       "      <td>198402886H</td>\n",
       "      <td>principal activities of the Company are to pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>VICOM LTD 2022 (198100320K).pdf</td>\n",
       "      <td>78</td>\n",
       "      <td>198100320K</td>\n",
       "      <td>principal activities of the Company are those ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             PDF Name  Page Number  \\\n",
       "0          ABR HOLDINGS LIMITED 2022 (197803023H).pdf           74   \n",
       "1   ABUNDANCE INTERNATIONAL LIMITED 2022 (19750157...           56   \n",
       "2             ABUNDANTE LIMITED 2023 (197902587H).pdf           48   \n",
       "3                ACCRELIST LTD. 2023 (201413466E).pdf           55   \n",
       "4      ACESIAN PARTNERS LIMITED 2022 (199505699D).pdf           54   \n",
       "..                                                ...          ...   \n",
       "82  TELECHOICE INTERNATIONAL LIMITED 2022 (1998020...          129   \n",
       "83     TT INTERNATIONAL LIMITED 2023 (198403771D).pdf           56   \n",
       "84  UNITED OVERSEAS INSURANCE LIMITED 2022 (197100...            4   \n",
       "85  VENTURE CORPORATION LIMITED 2022 (198402886H).pdf          107   \n",
       "86                    VICOM LTD 2022 (198100320K).pdf           78   \n",
       "\n",
       "    UEN Number                                 Notes Page Content  \n",
       "0   197803023H  principal activities of the Company are the ma...  \n",
       "1   197501572K  principal activities of the Company are those ...  \n",
       "2   197902587H  principal activities of the Company are those ...  \n",
       "3   201413466E  principal activities of the Company is investm...  \n",
       "4   199505699D  principal activities of the Group consist of d...  \n",
       "..         ...                                                ...  \n",
       "82  199802072R  principal activities of the Company during the...  \n",
       "83  198403771D  principal activities of the Company are those ...  \n",
       "84  197100152R        principal activities are the underwriting 1  \n",
       "85  198402886H  principal activities of the Company are to pro...  \n",
       "86  198100320K  principal activities of the Company are those ...  \n",
       "\n",
       "[87 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Files required for summarization\n",
    "df_for_Summary=pd.read_excel(\"../dataSources/ScrapedOutputFiles/10) extracted_notes_pages_with_uen.xlsx\")\n",
    "\n",
    "#SSIC Ref detailes\n",
    "SSIC_ref_df = pd.read_csv('SSIC Fact Ref Table.csv')\n",
    "SSIC_ref_df_test=SSIC_ref_df.head(10)\n",
    "#SSIC_ref_df_test\n",
    "df_for_Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Anaconda\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\",device=0)\n",
    "\n",
    "def get_answer(row):\n",
    "    context = row['Notes Page Content']\n",
    "    question = \"What are all the principal activities of the company? List down all the activities.\"  \n",
    "    result = pipe(question=question, context=context)\n",
    "    return result['answer']\n",
    "\n",
    "df_for_Summary['Q&A model Output'] = df_for_Summary.apply(get_answer, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_summarizer(summarizer, text, min_length=30, length_fraction=0.9, too_short_threshold=30):\n",
    "    input_length = len(text.split())\n",
    "    # If the text is shorter than the threshold, return original text\n",
    "    if input_length < too_short_threshold:\n",
    "        return text\n",
    "    max_length = int(input_length * length_fraction)\n",
    "    max_length = max(min_length, max_length)\n",
    "    summary=summarizer(text, max_length=max_length, min_length=min_length, do_sample=False)[0]['summary_text']\n",
    "    return summary\n",
    "\n",
    "df_for_Summary['Summarized_Description_azma_bart'] = df_for_Summary['Notes Page Content'].apply(\n",
    "    lambda x: dynamic_summarizer(summarizer_azma_bart, x)\n",
    ")\n",
    "df_for_Summary['Summarized_Description_facebook_bart'] = df_for_Summary['Notes Page Content'].apply(\n",
    "    lambda x: dynamic_summarizer(summarizer_facebook_bart, x)\n",
    ")\n",
    "df_for_Summary['Summarized_Description_philschmid_bart'] = df_for_Summary['Notes Page Content'].apply(\n",
    "    lambda x: dynamic_summarizer(summarizer_philschmid_bart, x)\n",
    ")\n",
    "\n",
    "#df_for_Summary['Length of original text'] =  df_for_Summary['Notes Page Content'].str.len()\n",
    "df_for_Summary['Input_length'] = df_for_Summary['Notes Page Content'].apply(lambda x: len(x.split()))\n",
    "\n",
    "df_for_Summary['Summarised?'] = df_for_Summary.apply(\n",
    "    lambda row: 'No' if row['Notes Page Content'] == row['Summarized_Description_azma_bart'] else 'Yes',axis=1\n",
    ")\n",
    "# df_for_Summary['Summarized_Description_azma_bart'] = df_for_Summary['Notes Page Content'].apply(\n",
    "#     lambda x: summarizer_azma_bart(x, max_length=150, min_length=30, do_sample=False)[0]['summary_text']\n",
    "# )\n",
    "# df_for_Summary['Summarized_Description_facebook_bart'] = df_for_Summary['Notes Page Content'].apply(\n",
    "#     lambda x: summarizer_facebook_bart(x, max_length=150, min_length=30, do_sample=False)[0]['summary_text']\n",
    "# )\n",
    "# df_for_Summary['Summarized_Description_philschmid_bart'] = df_for_Summary['Notes Page Content'].apply(\n",
    "#     lambda x: summarizer_philschmid_bart(x, max_length=150, min_length=30, do_sample=False)[0]['summary_text']\n",
    "# )\n",
    "\n",
    "# 85 rows - 5m 41s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_Summary.to_excel(\"D:\\ssicsync\\LLM_Test\\Summarised_output_for_model v2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################################\n",
    "# TDIDF\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "# nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    words_to_remove = ['principal','activity' ,'activities', 'investment', 'holding', 'holdings', 'singapore', 'exchange', 'securities', 'trading', 'limited', 'company']  # List of additional words to remove############################################################\n",
    "    # Remove additional words\n",
    "    if words_to_remove:\n",
    "        text = ' '.join(word for word in text.split() if word not in words_to_remove)\n",
    "    return text\n",
    "\n",
    "df_for_Summary['Azma_bart_tfidf'] = df_for_Summary['Summarized_Description_azma_bart'].apply(preprocess_text)\n",
    "df_for_Summary['FB_bart_tfidf'] = df_for_Summary['Summarized_Description_facebook_bart'].apply(preprocess_text)\n",
    "df_for_Summary['Philschmid_bart_tfidf'] = df_for_Summary['Summarized_Description_philschmid_bart'].apply(preprocess_text)\n",
    "\n",
    "# Fill NaN values in 'Azma_bart_tfidf' with 'Notes Page Content'\n",
    "df_for_Summary['Azma_bart_tfidf'] = df_for_Summary.apply(\n",
    "    lambda row: row['Notes Page Content'] if pd.isna(row['Azma_bart_tfidf']) else row['Azma_bart_tfidf'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_for_Summary['FB_bart_tfidf'] = df_for_Summary.apply(\n",
    "    lambda row: row['Notes Page Content'] if pd.isna(row['FB_bart_tfidf']) else row['FB_bart_tfidf'],\n",
    "    axis=1\n",
    ")\n",
    "df_for_Summary['Philschmid_bart_tfidf'] = df_for_Summary.apply(\n",
    "    lambda row: row['Notes Page Content'] if pd.isna(row['Philschmid_bart_tfidf']) else row['Philschmid_bart_tfidf'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    # # max_df=0.8,         # Ignore terms that appear in more than 80% of documents\n",
    "    # # min_df=2,           # Ignore terms that appear in fewer than 2 documents\n",
    "    # max_features=1000,  # Consider only the top 1000 terms by TF-IDF score\n",
    "    # ngram_range=(1, 2), # Include both unigrams and bigrams\n",
    "    # stop_words='english' # Remove standard English stop words\n",
    ")\n",
    "\n",
    "# Fit and transform the preprocessed text ('Notes Page Content2')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_for_Summary['Azma_bart_tfidf'])\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_for_Summary['FB_bart_tfidf'])  \n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_for_Summary['Philschmid_bart_tfidf'])\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_for_Summary['Q&A model Output_tfIDF'])\n",
    "\n",
    "# Get feature names (terms)\n",
    "terms = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Set a TF-IDF threshold\n",
    "tfidf_threshold = 0.1\n",
    "\n",
    "# Function to get important terms from a document\n",
    "def get_important_terms(doc_index, tfidf_matrix, terms, threshold, top_tokens=10):\n",
    "    term_scores = tfidf_matrix[doc_index].toarray().flatten()\n",
    "    important_term_indices = term_scores >= threshold\n",
    "    \n",
    "    # Filter terms based on threshold and preserve original order\n",
    "    important_terms = [terms[i] for i in range(len(terms)) if important_term_indices[i]]\n",
    "    \n",
    "    # Retrieve original order from 'Notes Page Content2'\n",
    "    original_text = df_for_Summary.at[doc_index, 'Azma_bart_tfidf'].split()\n",
    "    important_terms_in_order = [term for term in original_text if term in important_terms]\n",
    "\n",
    "    # Get the first 'top_tokens' tokens\n",
    "    first_10_tokens = important_terms_in_order[:top_tokens]\n",
    "    \n",
    "    return ' '.join(first_10_tokens )\n",
    "\n",
    "# Apply the function to each document in the DataFrame\n",
    "df_for_Summary['Azma_bart_tfidf']= [\n",
    "    get_important_terms(i, tfidf_matrix, terms, tfidf_threshold)\n",
    "    for i in range(tfidf_matrix.shape[0])\n",
    "]\n",
    "\n",
    "df_for_Summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_Summary.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "df_for_Summary.to_excel(\"Summarised_output_for_model.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SSIC 2020</th>\n",
       "      <th>SSIC 2020 Title</th>\n",
       "      <th>Detailed Definitions</th>\n",
       "      <th>Cross References</th>\n",
       "      <th>Examples of Activities Classified Under this Code</th>\n",
       "      <th>Section, 2 digit code</th>\n",
       "      <th>Division</th>\n",
       "      <th>Group</th>\n",
       "      <th>Class</th>\n",
       "      <th>Section</th>\n",
       "      <th>Section Title</th>\n",
       "      <th>Division Title</th>\n",
       "      <th>Group Title</th>\n",
       "      <th>Class Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1111</td>\n",
       "      <td>Growing of leafy and fruit vegetables</td>\n",
       "      <td>This sub-class includes the cultivation of lea...</td>\n",
       "      <td>•growing of mushrooms, see 01112\\r\\n•growing o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>111</td>\n",
       "      <td>A</td>\n",
       "      <td>AGRICULTURE AND FISHING</td>\n",
       "      <td>AGRICULTURE AND RELATED SERVICE ACTIVITIES</td>\n",
       "      <td>GROWING OF CROPS, MARKET GARDENING AND HORTICU...</td>\n",
       "      <td>Growing of Food Crops (Non-Hydroponics)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1112</td>\n",
       "      <td>Growing of mushrooms</td>\n",
       "      <td>This sub-class includes the cultivation of mus...</td>\n",
       "      <td>•growing of leafy and fruit vegetables (non-hy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>111</td>\n",
       "      <td>A</td>\n",
       "      <td>AGRICULTURE AND FISHING</td>\n",
       "      <td>AGRICULTURE AND RELATED SERVICE ACTIVITIES</td>\n",
       "      <td>GROWING OF CROPS, MARKET GARDENING AND HORTICU...</td>\n",
       "      <td>Growing of Food Crops (Non-Hydroponics)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1113</td>\n",
       "      <td>Growing of root crops</td>\n",
       "      <td>This sub-class includes the cultivation of roo...</td>\n",
       "      <td>•growing of leafy and fruit vegetables (non-hy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>111</td>\n",
       "      <td>A</td>\n",
       "      <td>AGRICULTURE AND FISHING</td>\n",
       "      <td>AGRICULTURE AND RELATED SERVICE ACTIVITIES</td>\n",
       "      <td>GROWING OF CROPS, MARKET GARDENING AND HORTICU...</td>\n",
       "      <td>Growing of Food Crops (Non-Hydroponics)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1119</td>\n",
       "      <td>Growing of food crops (non-hydroponics) n.e.c.</td>\n",
       "      <td>This sub-class includes the propagation of foo...</td>\n",
       "      <td>•growing of leafy and fruit vegetables (non-hy...</td>\n",
       "      <td>•cereals growing (non-hydroponics)\\r\\n•rice gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>111</td>\n",
       "      <td>A</td>\n",
       "      <td>AGRICULTURE AND FISHING</td>\n",
       "      <td>AGRICULTURE AND RELATED SERVICE ACTIVITIES</td>\n",
       "      <td>GROWING OF CROPS, MARKET GARDENING AND HORTICU...</td>\n",
       "      <td>Growing of Food Crops (Non-Hydroponics)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1120</td>\n",
       "      <td>Growing of leafy and fruit vegetables (hydropo...</td>\n",
       "      <td>This sub-class includes the cultivation of lea...</td>\n",
       "      <td>•growing of leafy and fruit vegetables (non-hy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>112</td>\n",
       "      <td>A</td>\n",
       "      <td>AGRICULTURE AND FISHING</td>\n",
       "      <td>AGRICULTURE AND RELATED SERVICE ACTIVITIES</td>\n",
       "      <td>GROWING OF CROPS, MARKET GARDENING AND HORTICU...</td>\n",
       "      <td>Growing of Food Crops (Hydroponics)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>97001</td>\n",
       "      <td>Activities of households as employers of domes...</td>\n",
       "      <td>This Sub-class includes activities of househol...</td>\n",
       "      <td>•activities of households as employers of othe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>970</td>\n",
       "      <td>9700</td>\n",
       "      <td>T</td>\n",
       "      <td>ACTIVITIES OF HOUSEHOLDS AS EMPLOYERS OF DOMES...</td>\n",
       "      <td>ACTIVITIES OF HOUSEHOLDS AS EMPLOYERS OF DOMES...</td>\n",
       "      <td>ACTIVITIES OF HOUSEHOLDS AS EMPLOYERS OF DOMES...</td>\n",
       "      <td>Activities of Households as Employers of Domes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>97002</td>\n",
       "      <td>Activities of households as employers of other...</td>\n",
       "      <td>This Sub-class includes activities of househol...</td>\n",
       "      <td>•activities of households as employers of dome...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>970</td>\n",
       "      <td>9700</td>\n",
       "      <td>T</td>\n",
       "      <td>ACTIVITIES OF HOUSEHOLDS AS EMPLOYERS OF DOMES...</td>\n",
       "      <td>ACTIVITIES OF HOUSEHOLDS AS EMPLOYERS OF DOMES...</td>\n",
       "      <td>ACTIVITIES OF HOUSEHOLDS AS EMPLOYERS OF DOMES...</td>\n",
       "      <td>Activities of Households as Employers of Domes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>99010</td>\n",
       "      <td>Foreign embassies and trade representative off...</td>\n",
       "      <td>This Sub-class includes activities of: \\r\\n•di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>990</td>\n",
       "      <td>9901</td>\n",
       "      <td>U</td>\n",
       "      <td>ACTIVITIES OF EXTRA-TERRITORIAL ORGANISATIONS ...</td>\n",
       "      <td>ACTIVITIES OF EXTRA-TERRITORIAL ORGANISATIONS ...</td>\n",
       "      <td>ACTIVITIES OF EXTRA-TERRITORIAL ORGANISATIONS ...</td>\n",
       "      <td>Foreign Embassies and Trade Representative Off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>99020</td>\n",
       "      <td>Foreign armed forces</td>\n",
       "      <td>This Sub-class includes activities of foreign ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>990</td>\n",
       "      <td>9902</td>\n",
       "      <td>U</td>\n",
       "      <td>ACTIVITIES OF EXTRA-TERRITORIAL ORGANISATIONS ...</td>\n",
       "      <td>ACTIVITIES OF EXTRA-TERRITORIAL ORGANISATIONS ...</td>\n",
       "      <td>ACTIVITIES OF EXTRA-TERRITORIAL ORGANISATIONS ...</td>\n",
       "      <td>Foreign Armed Forces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>99090</td>\n",
       "      <td>Other extra-territorial organisations and bodies</td>\n",
       "      <td>This Sub-class includes activities of other in...</td>\n",
       "      <td>•activities of foreign embassies and trade rep...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>990</td>\n",
       "      <td>9909</td>\n",
       "      <td>U</td>\n",
       "      <td>ACTIVITIES OF EXTRA-TERRITORIAL ORGANISATIONS ...</td>\n",
       "      <td>ACTIVITIES OF EXTRA-TERRITORIAL ORGANISATIONS ...</td>\n",
       "      <td>ACTIVITIES OF EXTRA-TERRITORIAL ORGANISATIONS ...</td>\n",
       "      <td>Other Extra-territorial Organisations and Bodies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1023 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SSIC 2020                                    SSIC 2020 Title  \\\n",
       "0          1111              Growing of leafy and fruit vegetables   \n",
       "1          1112                               Growing of mushrooms   \n",
       "2          1113                              Growing of root crops   \n",
       "3          1119     Growing of food crops (non-hydroponics) n.e.c.   \n",
       "4          1120  Growing of leafy and fruit vegetables (hydropo...   \n",
       "...         ...                                                ...   \n",
       "1018      97001  Activities of households as employers of domes...   \n",
       "1019      97002  Activities of households as employers of other...   \n",
       "1020      99010  Foreign embassies and trade representative off...   \n",
       "1021      99020                               Foreign armed forces   \n",
       "1022      99090   Other extra-territorial organisations and bodies   \n",
       "\n",
       "                                   Detailed Definitions  \\\n",
       "0     This sub-class includes the cultivation of lea...   \n",
       "1     This sub-class includes the cultivation of mus...   \n",
       "2     This sub-class includes the cultivation of roo...   \n",
       "3     This sub-class includes the propagation of foo...   \n",
       "4     This sub-class includes the cultivation of lea...   \n",
       "...                                                 ...   \n",
       "1018  This Sub-class includes activities of househol...   \n",
       "1019  This Sub-class includes activities of househol...   \n",
       "1020  This Sub-class includes activities of: \\r\\n•di...   \n",
       "1021  This Sub-class includes activities of foreign ...   \n",
       "1022  This Sub-class includes activities of other in...   \n",
       "\n",
       "                                       Cross References  \\\n",
       "0     •growing of mushrooms, see 01112\\r\\n•growing o...   \n",
       "1     •growing of leafy and fruit vegetables (non-hy...   \n",
       "2     •growing of leafy and fruit vegetables (non-hy...   \n",
       "3     •growing of leafy and fruit vegetables (non-hy...   \n",
       "4     •growing of leafy and fruit vegetables (non-hy...   \n",
       "...                                                 ...   \n",
       "1018  •activities of households as employers of othe...   \n",
       "1019  •activities of households as employers of dome...   \n",
       "1020                                                NaN   \n",
       "1021                                                NaN   \n",
       "1022  •activities of foreign embassies and trade rep...   \n",
       "\n",
       "      Examples of Activities Classified Under this Code  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3     •cereals growing (non-hydroponics)\\r\\n•rice gr...   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "1018                                                NaN   \n",
       "1019                                                NaN   \n",
       "1020                                                NaN   \n",
       "1021                                                NaN   \n",
       "1022                                                NaN   \n",
       "\n",
       "      Section, 2 digit code  Division  Group  Class Section  \\\n",
       "0                         1         1     11    111       A   \n",
       "1                         1         1     11    111       A   \n",
       "2                         1         1     11    111       A   \n",
       "3                         1         1     11    111       A   \n",
       "4                         1         1     11    112       A   \n",
       "...                     ...       ...    ...    ...     ...   \n",
       "1018                     97        97    970   9700       T   \n",
       "1019                     97        97    970   9700       T   \n",
       "1020                     99        99    990   9901       U   \n",
       "1021                     99        99    990   9902       U   \n",
       "1022                     99        99    990   9909       U   \n",
       "\n",
       "                                          Section Title  \\\n",
       "0                               AGRICULTURE AND FISHING   \n",
       "1                               AGRICULTURE AND FISHING   \n",
       "2                               AGRICULTURE AND FISHING   \n",
       "3                               AGRICULTURE AND FISHING   \n",
       "4                               AGRICULTURE AND FISHING   \n",
       "...                                                 ...   \n",
       "1018  ACTIVITIES OF HOUSEHOLDS AS EMPLOYERS OF DOMES...   \n",
       "1019  ACTIVITIES OF HOUSEHOLDS AS EMPLOYERS OF DOMES...   \n",
       "1020  ACTIVITIES OF EXTRA-TERRITORIAL ORGANISATIONS ...   \n",
       "1021  ACTIVITIES OF EXTRA-TERRITORIAL ORGANISATIONS ...   \n",
       "1022  ACTIVITIES OF EXTRA-TERRITORIAL ORGANISATIONS ...   \n",
       "\n",
       "                                         Division Title  \\\n",
       "0            AGRICULTURE AND RELATED SERVICE ACTIVITIES   \n",
       "1            AGRICULTURE AND RELATED SERVICE ACTIVITIES   \n",
       "2            AGRICULTURE AND RELATED SERVICE ACTIVITIES   \n",
       "3            AGRICULTURE AND RELATED SERVICE ACTIVITIES   \n",
       "4            AGRICULTURE AND RELATED SERVICE ACTIVITIES   \n",
       "...                                                 ...   \n",
       "1018  ACTIVITIES OF HOUSEHOLDS AS EMPLOYERS OF DOMES...   \n",
       "1019  ACTIVITIES OF HOUSEHOLDS AS EMPLOYERS OF DOMES...   \n",
       "1020  ACTIVITIES OF EXTRA-TERRITORIAL ORGANISATIONS ...   \n",
       "1021  ACTIVITIES OF EXTRA-TERRITORIAL ORGANISATIONS ...   \n",
       "1022  ACTIVITIES OF EXTRA-TERRITORIAL ORGANISATIONS ...   \n",
       "\n",
       "                                            Group Title  \\\n",
       "0     GROWING OF CROPS, MARKET GARDENING AND HORTICU...   \n",
       "1     GROWING OF CROPS, MARKET GARDENING AND HORTICU...   \n",
       "2     GROWING OF CROPS, MARKET GARDENING AND HORTICU...   \n",
       "3     GROWING OF CROPS, MARKET GARDENING AND HORTICU...   \n",
       "4     GROWING OF CROPS, MARKET GARDENING AND HORTICU...   \n",
       "...                                                 ...   \n",
       "1018  ACTIVITIES OF HOUSEHOLDS AS EMPLOYERS OF DOMES...   \n",
       "1019  ACTIVITIES OF HOUSEHOLDS AS EMPLOYERS OF DOMES...   \n",
       "1020  ACTIVITIES OF EXTRA-TERRITORIAL ORGANISATIONS ...   \n",
       "1021  ACTIVITIES OF EXTRA-TERRITORIAL ORGANISATIONS ...   \n",
       "1022  ACTIVITIES OF EXTRA-TERRITORIAL ORGANISATIONS ...   \n",
       "\n",
       "                                            Class Title  \n",
       "0               Growing of Food Crops (Non-Hydroponics)  \n",
       "1               Growing of Food Crops (Non-Hydroponics)  \n",
       "2               Growing of Food Crops (Non-Hydroponics)  \n",
       "3               Growing of Food Crops (Non-Hydroponics)  \n",
       "4                   Growing of Food Crops (Hydroponics)  \n",
       "...                                                 ...  \n",
       "1018  Activities of Households as Employers of Domes...  \n",
       "1019  Activities of Households as Employers of Domes...  \n",
       "1020  Foreign Embassies and Trade Representative Off...  \n",
       "1021                               Foreign Armed Forces  \n",
       "1022   Other Extra-territorial Organisations and Bodies  \n",
       "\n",
       "[1023 rows x 14 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSIC_ref_df = SSIC_ref_df.drop_duplicates(subset=['SSIC 2020'], keep='first')\n",
    "SSIC_ref_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_Summary = pd.read_excel(\"D:\\ssicsync\\LLM_Test\\Summarised_output_for_model.xlsx\", dtype = str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\4137931732.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\4137931732.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\4137931732.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\4137931732.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\4137931732.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDF Name</th>\n",
       "      <th>llm_output_llama3.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACCRELIST LTD. 2023 (201413466E).pdf</td>\n",
       "      <td>I don't see any section labeled \"NOTES TO THE FINANCIAL STATEMENTS\". However, I can try to extract the principle activity from other relevant sections. \\n\\nBased on the provided text, the company's name is ACCRELIST HOLDINGS LIMITED and the following keywords are related to their activities:\\n\\n* \"Technology\"\\n* \"Software\"\\n* \"Digital Media\"\\n\\nThese keywords might be related to the company's principal activities, but without more context or specific information from a \"NOTES TO THE FINANCIAL STATEMENTS\" section, it is difficult to confirm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CREATIVE TECHNOLOGY LTD. 2023 (198303359D).pdf</td>\n",
       "      <td>Based on the provided information, I was unable to find a section titled \"NOTES TO THE FINANCIAL STATEMENTS\". However, I can help you extract the principle activity from other available information.\\n\\nFrom the \"CORPORATE INFORMATION\" section:\\n\\n* Company Name: CREATIVE TECHNOLOGY LTD. AND ITS SUBSIDIARIES\\n* Tagline: creative.com\\n\\nAssuming this is related to the company's principle activity:\\n\\n**Digital Technology / E-commerce**\\n\\nPlease note that I had to make an educated guess based on the provided information, and it may not be entirely accurate. If you have any additional context or details, please feel free to provide them!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NANOFILM TECHNOLOGIES INTERNATIONAL LIMITED 2022 (199902564C).pdf</td>\n",
       "      <td>Here is the extracted information:\\n\\n**\"NOTES TO THE FINANCIAL STATEMENTS\"**\\n\\n* Operating segment: **Manufacturing of coatings and surface technologies**\\n* Principal activities:\\n\\t+ Development, manufacture and sale of various nanocoating products \\n\\t+ Supply of technical services to customers in connection with the use of its coating products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABR HOLDINGS LIMITED 2022 (197803023H).pdf</td>\n",
       "      <td>Here is the extracted principle activity:\\n\\n\"Property investment and property development, and provision of related services\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNITED OVERSEAS INSURANCE LIMITED 2022 (197100152R).pdf</td>\n",
       "      <td>Financial Services \\nInsurance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            PDF Name  \\\n",
       "0                               ACCRELIST LTD. 2023 (201413466E).pdf   \n",
       "1                     CREATIVE TECHNOLOGY LTD. 2023 (198303359D).pdf   \n",
       "2  NANOFILM TECHNOLOGIES INTERNATIONAL LIMITED 2022 (199902564C).pdf   \n",
       "3                         ABR HOLDINGS LIMITED 2022 (197803023H).pdf   \n",
       "4            UNITED OVERSEAS INSURANCE LIMITED 2022 (197100152R).pdf   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  llm_output_llama3.1  \n",
       "0                                                                                                  I don't see any section labeled \"NOTES TO THE FINANCIAL STATEMENTS\". However, I can try to extract the principle activity from other relevant sections. \\n\\nBased on the provided text, the company's name is ACCRELIST HOLDINGS LIMITED and the following keywords are related to their activities:\\n\\n* \"Technology\"\\n* \"Software\"\\n* \"Digital Media\"\\n\\nThese keywords might be related to the company's principal activities, but without more context or specific information from a \"NOTES TO THE FINANCIAL STATEMENTS\" section, it is difficult to confirm.  \n",
       "1  Based on the provided information, I was unable to find a section titled \"NOTES TO THE FINANCIAL STATEMENTS\". However, I can help you extract the principle activity from other available information.\\n\\nFrom the \"CORPORATE INFORMATION\" section:\\n\\n* Company Name: CREATIVE TECHNOLOGY LTD. AND ITS SUBSIDIARIES\\n* Tagline: creative.com\\n\\nAssuming this is related to the company's principle activity:\\n\\n**Digital Technology / E-commerce**\\n\\nPlease note that I had to make an educated guess based on the provided information, and it may not be entirely accurate. If you have any additional context or details, please feel free to provide them!  \n",
       "2                                                                                                                                                                                                                                                                                                     Here is the extracted information:\\n\\n**\"NOTES TO THE FINANCIAL STATEMENTS\"**\\n\\n* Operating segment: **Manufacturing of coatings and surface technologies**\\n* Principal activities:\\n\\t+ Development, manufacture and sale of various nanocoating products \\n\\t+ Supply of technical services to customers in connection with the use of its coating products  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Here is the extracted principle activity:\\n\\n\"Property investment and property development, and provision of related services\"  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Financial Services \\nInsurance  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "list_model_name = ['llama3.1']\n",
    "\n",
    "# Define the function to extract and summarize the business activity\n",
    "def summarize_business_activity(content, model_name):\n",
    "    response = ollama.chat(model=model_name, messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': f'''\n",
    "            {content}\n",
    "\n",
    "            \n",
    "            extract the principal activity under \"NOTES TO THE FINANCIAL STATEMENTS\" sections in keywords only\n",
    "            ''',\n",
    "        },\n",
    "\n",
    "    #extract \n",
    "    ])  # Specify the device\n",
    "    response_v = response['message']['content']  # Get the response content\n",
    "    return response_v\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# List of PDF files to process\n",
    "pdf_directory = \"D:/ssicsync/input_rawPDFReports/\"\n",
    "#pdf_files = [os.path.join(pdf_directory, f) for f in os.listdir(pdf_directory) if f.endswith('.pdf')]\n",
    "\n",
    "#Test on certain files only\n",
    "specific_pdf_files = [\n",
    "    \"ACCRELIST LTD. 2023 (201413466E).pdf\",\n",
    "    \"CREATIVE TECHNOLOGY LTD. 2023 (198303359D).pdf\",\n",
    "    \"NANOFILM TECHNOLOGIES INTERNATIONAL LIMITED 2022 (199902564C).pdf\",\n",
    "    \"ABR HOLDINGS LIMITED 2022 (197803023H).pdf\",\n",
    "    \"UNITED OVERSEAS INSURANCE LIMITED 2022 (197100152R).pdf\"\n",
    "]\n",
    "pdf_files = [os.path.join(pdf_directory, f) for f in specific_pdf_files]\n",
    "\n",
    "# DataFrame to store results\n",
    "df_results = pd.DataFrame(columns=['PDF File', 'Extracted Text'] + [f'llm_output_{model}' for model in list_model_name])\n",
    "\n",
    "#\n",
    "# Process each PDF file\n",
    "for pdf_file in pdf_files:\n",
    "    extracted_text = extract_text_from_pdf(pdf_file)\n",
    "    result_row = {'PDF File': pdf_file, 'Extracted Text': extracted_text}\n",
    "    \n",
    "    for model in list_model_name:\n",
    "        column_name = 'llm_output_' + model\n",
    "        result_row[column_name] = summarize_business_activity(extracted_text, model)\n",
    "    \n",
    "    df_results = df_results.append(result_row, ignore_index=True)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# Save the results to an Excel file if needed\n",
    "# df_results.to_excel('summarized_output.xlsx', index=False)\n",
    "df_results['PDF Name'] = df_results['PDF File'].apply(lambda x: os.path.basename(x))\n",
    "df_results.loc[:,['PDF Name', 'llm_output_llama3.1']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8900\\799553894.py:46: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_row, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDF Name</th>\n",
       "      <th>llm_output_llama3.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABR HOLDINGS LIMITED 2022 (197803023H).pdf</td>\n",
       "      <td>Investment Holding Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABUNDANCE INTERNATIONAL LIMITED 2022 (197501572K).pdf</td>\n",
       "      <td>Investment Holding Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABUNDANTE LIMITED 2023 (197902587H).pdf</td>\n",
       "      <td>Here are the principal activities extracted from the text:\\n\\n* Property investment and development\\n* Hotel operation\\n* Management of hotels and other properties\\n* Trading and investment activities\\n* Financing and investment activities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACCRELIST LTD. 2023 (201413466E).pdf</td>\n",
       "      <td>Here are the extracted principal activities in keywords only:\\n\\n* Provision of information and consulting services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACESIAN PARTNERS LIMITED 2022 (199505699D).pdf</td>\n",
       "      <td>No principal activity mentioned in the provided text. \\n\\nHowever, I can try to help you with other information extraction tasks if needed!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                PDF Name  \\\n",
       "0             ABR HOLDINGS LIMITED 2022 (197803023H).pdf   \n",
       "1  ABUNDANCE INTERNATIONAL LIMITED 2022 (197501572K).pdf   \n",
       "2                ABUNDANTE LIMITED 2023 (197902587H).pdf   \n",
       "3                   ACCRELIST LTD. 2023 (201413466E).pdf   \n",
       "4         ACESIAN PARTNERS LIMITED 2022 (199505699D).pdf   \n",
       "\n",
       "                                                                                                                                                                                                                               llm_output_llama3.1  \n",
       "0                                                                                                                                                                                                                       Investment Holding Company  \n",
       "1                                                                                                                                                                                                                       Investment Holding Company  \n",
       "2  Here are the principal activities extracted from the text:\\n\\n* Property investment and development\\n* Hotel operation\\n* Management of hotels and other properties\\n* Trading and investment activities\\n* Financing and investment activities  \n",
       "3                                                                                                                              Here are the extracted principal activities in keywords only:\\n\\n* Provision of information and consulting services  \n",
       "4                                                                                                      No principal activity mentioned in the provided text. \\n\\nHowever, I can try to help you with other information extraction tasks if needed!  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_model_name = ['llama3.1']\n",
    "\n",
    "# Define the function to extract and summarize the business activity\n",
    "def summarize_business_activity(content, model_name):\n",
    "    response = ollama.chat(model=model_name, messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': f'''\n",
    "            {content}\n",
    "\n",
    "            \n",
    "            extract the principal activity under \"NOTES TO THE FINANCIAL STATEMENTS\" sections in keywords only\n",
    "            ''',\n",
    "        },\n",
    "\n",
    "    #extract \n",
    "    ])  # Specify the device\n",
    "    response_v = response['message']['content']  # Get the response content\n",
    "    return response_v\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# List of PDF files to process\n",
    "pdf_directory = \"D:/ssicsync/input_rawPDFReports/\"\n",
    "pdf_files = [os.path.join(pdf_directory, f) for f in os.listdir(pdf_directory) if f.endswith('.pdf')]\n",
    "\n",
    "# DataFrame to store results\n",
    "df_results = pd.DataFrame(columns=['PDF File', 'Extracted Text'] + [f'llm_output_{model}' for model in list_model_name])\n",
    "\n",
    "#\n",
    "# Process each PDF file\n",
    "for pdf_file in pdf_files:\n",
    "    extracted_text = extract_text_from_pdf(pdf_file)\n",
    "    result_row = {'PDF File': pdf_file, 'Extracted Text': extracted_text}\n",
    "    \n",
    "    for model in list_model_name:\n",
    "        column_name = 'llm_output_' + model\n",
    "        result_row[column_name] = summarize_business_activity(extracted_text, model)\n",
    "    \n",
    "    df_results = df_results.append(result_row, ignore_index=True)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# Save the results to an Excel file if needed\n",
    "# df_results.to_excel('summarized_output.xlsx', index=False)\n",
    "df_results['PDF Name'] = df_results['PDF File'].apply(lambda x: os.path.basename(x))\n",
    "df_results.loc[:,['PDF Name', 'llm_output_llama3.1']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_for_Summary, df_results[['PDF Name', 'llm_output_llama3.1']], left_on='PDF Name', right_on='PDF Name', how='left')\n",
    "#merged_df.to_excel(\"D:\\ssicsync\\LLM_Test\\Summarised_output_for_model_v3.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm_output_llama3.1_tfidf</th>\n",
       "      <th>llm_output_llama3.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Investment Holding Company</td>\n",
       "      <td>Investment Holding Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investment Holding Company</td>\n",
       "      <td>Investment Holding Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text property development hotel operation management hotels properties financing</td>\n",
       "      <td>Here are the principal activities extracted from the text:\\n\\n* Property investment and development\\n* Hotel operation\\n* Management of hotels and other properties\\n* Trading and investment activities\\n* Financing and investment activities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>provision information consulting services</td>\n",
       "      <td>Here are the extracted principal activities in keywords only:\\n\\n* Provision of information and consulting services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mentioned provided text however try help information extraction tasks needed</td>\n",
       "      <td>No principal activity mentioned in the provided text. \\n\\nHowever, I can try to help you with other information extraction tasks if needed!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>provided text telecommunications services equipment rental provision communication network infrastructure</td>\n",
       "      <td>Here are the principal activities extracted from the provided text:\\n\\n* Telecommunications services and equipment rental\\n* Provision of communication network infrastructure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>manufacturing electronic components</td>\n",
       "      <td>Manufacturing &amp; Trading of Electronic Components</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>insurance providing general insurance reinsurance business general insurance business life</td>\n",
       "      <td>Insurance services \\n\\nproviding general insurance \\n\\nreinsurance business \\n\\ngeneral insurance business \\n\\nlife reinsurance business \\n\\ninvestment activities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>notes financial statements section provision services goods manufacturing precision components</td>\n",
       "      <td>Here are the principal activities extracted from the \"NOTES TO THE FINANCIAL STATEMENTS\" section in keywords only:\\n\\n* Provision of services\\n* Trading in goods\\n* Manufacturing and trading of precision components</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>dont see mention however try help information related vicom ltd</td>\n",
       "      <td>I don't see any mention of a \"principal activity\" under the \"NOTES TO THE FINANCIAL STATEMENTS\" section. However, I can try to help you with other information related to Vicom Ltd.\\n\\nHowever, based on my previous conversation with you, it appears that we were discussing a proxy form for Vicol Ltd's 42nd Annual General Meeting (AGM) held at ComfortDelGro Corporation's Headquarters, located at 205 Braddell Road, Singapore 579701.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                    llm_output_llama3.1_tfidf  \\\n",
       "0                                                                                  Investment Holding Company   \n",
       "1                                                                                  Investment Holding Company   \n",
       "2                            text property development hotel operation management hotels properties financing   \n",
       "3                                                                   provision information consulting services   \n",
       "4                                mentioned provided text however try help information extraction tasks needed   \n",
       "..                                                                                                        ...   \n",
       "82  provided text telecommunications services equipment rental provision communication network infrastructure   \n",
       "83                                                                        manufacturing electronic components   \n",
       "84                 insurance providing general insurance reinsurance business general insurance business life   \n",
       "85             notes financial statements section provision services goods manufacturing precision components   \n",
       "86                                            dont see mention however try help information related vicom ltd   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                 llm_output_llama3.1  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                         Investment Holding Company  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                         Investment Holding Company  \n",
       "2                                                                                                                                                                                                    Here are the principal activities extracted from the text:\\n\\n* Property investment and development\\n* Hotel operation\\n* Management of hotels and other properties\\n* Trading and investment activities\\n* Financing and investment activities  \n",
       "3                                                                                                                                                                                                                                                                                                                                Here are the extracted principal activities in keywords only:\\n\\n* Provision of information and consulting services  \n",
       "4                                                                                                                                                                                                                                                                                                        No principal activity mentioned in the provided text. \\n\\nHowever, I can try to help you with other information extraction tasks if needed!  \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                               ...  \n",
       "82                                                                                                                                                                                                                                                                    Here are the principal activities extracted from the provided text:\\n\\n* Telecommunications services and equipment rental\\n* Provision of communication network infrastructure  \n",
       "83                                                                                                                                                                                                                                                                                                                                                                                                  Manufacturing & Trading of Electronic Components  \n",
       "84                                                                                                                                                                                                                                                                                Insurance services \\n\\nproviding general insurance \\n\\nreinsurance business \\n\\ngeneral insurance business \\n\\nlife reinsurance business \\n\\ninvestment activities  \n",
       "85                                                                                                                                                                                                                            Here are the principal activities extracted from the \"NOTES TO THE FINANCIAL STATEMENTS\" section in keywords only:\\n\\n* Provision of services\\n* Trading in goods\\n* Manufacturing and trading of precision components  \n",
       "86  I don't see any mention of a \"principal activity\" under the \"NOTES TO THE FINANCIAL STATEMENTS\" section. However, I can try to help you with other information related to Vicom Ltd.\\n\\nHowever, based on my previous conversation with you, it appears that we were discussing a proxy form for Vicol Ltd's 42nd Annual General Meeting (AGM) held at ComfortDelGro Corporation's Headquarters, located at 205 Braddell Road, Singapore 579701.  \n",
       "\n",
       "[87 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Preprocess text function\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    words_to_remove = ['principal', 'activity', 'activities', 'investment', 'holding', 'holdings', 'singapore', 'exchange', 'securities', 'trading', 'limited', 'company','extracted','keywords']  # List of additional words to remove\n",
    "    # Remove additional words\n",
    "    text = ' '.join(word for word in text.split() if word not in words_to_remove)\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to the 'llm_output_llama3.1' column\n",
    "merged_df['llm_output_llama3.1_tfidf'] = merged_df['llm_output_llama3.1'].apply(preprocess_text)\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the preprocessed text\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(merged_df['llm_output_llama3.1_tfidf'])\n",
    "\n",
    "# Get feature names (terms)\n",
    "terms = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Set a TF-IDF threshold\n",
    "tfidf_threshold = 0.1\n",
    "\n",
    "# Function to get important terms from a document\n",
    "def get_important_terms(doc_index, tfidf_matrix, terms, threshold, top_tokens=10):\n",
    "    term_scores = tfidf_matrix[doc_index].toarray().flatten()\n",
    "    important_term_indices = term_scores >= threshold\n",
    "    \n",
    "    # Filter terms based on threshold and preserve original order\n",
    "    important_terms = [terms[i] for i in range(len(terms)) if important_term_indices[i]]\n",
    "    \n",
    "    # Retrieve original order from 'llm_output_llama3.1_tfidf'\n",
    "    original_text = merged_df.at[doc_index, 'llm_output_llama3.1_tfidf'].split()\n",
    "    important_terms_in_order = [term for term in original_text if term in important_terms]\n",
    "\n",
    "    # Get the first 'top_tokens' tokens\n",
    "    first_10_tokens = important_terms_in_order[:top_tokens]\n",
    "    \n",
    "    return ' '.join(first_10_tokens)\n",
    "\n",
    "# Apply the function to each document in the DataFrame\n",
    "merged_df['llm_output_llama3.1_tfidf'] = [\n",
    "    get_important_terms(i, tfidf_matrix, terms, tfidf_threshold)\n",
    "    for i in range(tfidf_matrix.shape[0])\n",
    "]\n",
    "\n",
    "# Check for empty TF-IDF outputs and replace with original content if empty\n",
    "merged_df['llm_output_llama3.1_tfidf'] = merged_df.apply(\n",
    "    lambda row: row['llm_output_llama3.1'] if not row['llm_output_llama3.1_tfidf'] else row['llm_output_llama3.1_tfidf'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Display the modified DataFrame\n",
    "merged_df.loc[:,['llm_output_llama3.1_tfidf', 'llm_output_llama3.1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_excel(\"D:\\ssicsync\\LLM_Test\\Summarised_output_for_model_v3.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KeyBert\n",
    "https://github.com/MaartenGr/KeyBERT\n",
    "\n",
    "Embedding documents; \n",
    "Creating candidate keywords; \n",
    "Calculating best keywords through either MMR, Max Sum Similarity, or Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('principal activities', 0.6735),\n",
       " ('activities subsidiaries', 0.5877),\n",
       " ('activities company', 0.4743),\n",
       " ('subsidiaries trading', 0.4476),\n",
       " ('activities investment', 0.409),\n",
       " ('holding principal', 0.3914),\n",
       " ('chemical products', 0.3815),\n",
       " ('company print', 0.3769),\n",
       " ('paper management', 0.3719),\n",
       " ('related activities', 0.3711)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "# description = \"\"\"principal activities of the Company are the prefabrication of steel reinforcement for use in concrete, \n",
    "# trading of steel reinforcing bars, and manufacturing and sale of wire mesh fences. \n",
    "# The principal activities of the subsidiaries are disclosed in Note 13 to the financial statements. \n",
    "# \"\"\"\n",
    "description = \"\"\"principal activities of the Company are those of print and paper management related activities and investment holding. \n",
    "The principal activities of the subsidiaries are those of trading of commodity chemical products, \n",
    "provision of water treatment solutions using microbial and/or chemicals in the People s Republic of China ( PRC ), \n",
    "print and paper management related activities and in investment and trading of securities.\n",
    "\"\"\"\n",
    "\n",
    "#keyphrase_ngram_range ---->  depending on the number of words in the resulting keyphrases\n",
    "keywords = KeyBERT().extract_keywords(description,keyphrase_ngram_range=(2, 2),top_n=10)\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply keybert on ref table, change the range accordinly\n",
    "SSIC_ref_df['Keywords'] = SSIC_ref_df['Detailed Definitions'].apply(\n",
    "    lambda x: kw_model.extract_keywords(x, keyphrase_ngram_range=(2, 2))\n",
    ")\n",
    "\n",
    "SSIC_ref_df['Keywords']\n",
    "#return: keywords: The top n keywords for a document with their respective distancesto the input document.\n",
    "SSIC_ref_df.to_excel(\"SSIC Fact Ref_with keywords.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare keywords got from description\n",
    "for _, row in SSIC_ref_df.iterrows():\n",
    "    fact_keywords = [kw[0] for kw in row['Keywords']]\n",
    "    new_submission_keywords = [kw[0] for kw in keywords]\n",
    "    match = set(fact_keywords).intersection(set(new_submission_keywords))\n",
    "    \n",
    "    if match:\n",
    "        print(f\"Matching SSIC: {row['SSIC 2020']}, Keywords: {match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6884\\3277016640.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_linkedin['Embeddings'] = (test_linkedin.head(10))['Summarized_Description'].apply(lambda x: model.encode(x))\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6884\\3277016640.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_ssicref['Embeddings'] = test_ssicref['Detailed Definitions'].apply(lambda x: model.encode(x))\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6884\\3277016640.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_linkedin['Best_Match_SSIC'] = matches.apply(lambda x: x[0])\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6884\\3277016640.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_linkedin['Best_Match_Definition'] = matches.apply(lambda x: x[2])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDF Name</th>\n",
       "      <th>Page Number</th>\n",
       "      <th>Notes Page Content</th>\n",
       "      <th>Summarized_Description</th>\n",
       "      <th>Embeddings</th>\n",
       "      <th>Best_Match_SSIC</th>\n",
       "      <th>Best_Match_Definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABR HOLDINGS LIMITED 2022.pdf</td>\n",
       "      <td>74</td>\n",
       "      <td>principal activities of the Company are the ma...</td>\n",
       "      <td>The principal activities of the Company are th...</td>\n",
       "      <td>[-0.020132285, -0.10326839, -0.01515015, 0.012...</td>\n",
       "      <td>1120</td>\n",
       "      <td>This sub-class includes the cultivation of lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABUNDANCE INTERNATIONAL LIMITED 2022.pdf</td>\n",
       "      <td>56</td>\n",
       "      <td>principal activities of the Company are those ...</td>\n",
       "      <td>The principal activities of the Company are th...</td>\n",
       "      <td>[-0.033344787, -0.049288258, 0.022993648, -0.0...</td>\n",
       "      <td>1190</td>\n",
       "      <td>This Sub-class includes the growing of other c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABUNDANTE LIMITED 2023.pdf</td>\n",
       "      <td>48</td>\n",
       "      <td>principal activities of the Company are those ...</td>\n",
       "      <td>The Company's ultimate controlling party is Le...</td>\n",
       "      <td>[-0.07526265, -0.040298507, 0.029111238, 0.032...</td>\n",
       "      <td>1111</td>\n",
       "      <td>This sub-class includes the cultivation of lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACCRELIST LTD. 2023.pdf</td>\n",
       "      <td>55</td>\n",
       "      <td>principal activities of the Company is investm...</td>\n",
       "      <td>The principal activities of the Company are in...</td>\n",
       "      <td>[-0.0043711183, -0.050210413, -0.010950963, -0...</td>\n",
       "      <td>1190</td>\n",
       "      <td>This Sub-class includes the growing of other c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACESIAN PARTNERS LIMITED 2022.pdf</td>\n",
       "      <td>54</td>\n",
       "      <td>principal activities of the Group consist of d...</td>\n",
       "      <td>The principal activities of the Group consist ...</td>\n",
       "      <td>[-0.0027161513, 0.0018759626, -0.027635382, -0...</td>\n",
       "      <td>1190</td>\n",
       "      <td>This Sub-class includes the growing of other c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACMA LTD. 2022.pdf</td>\n",
       "      <td>48</td>\n",
       "      <td>principal activity of the Company is that of i...</td>\n",
       "      <td>The principal activity of Acma Ltd. is that of...</td>\n",
       "      <td>[-0.046834115, 0.02470865, -0.029877186, -0.02...</td>\n",
       "      <td>1190</td>\n",
       "      <td>This Sub-class includes the growing of other c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ADVANCED SYSTEMS AUTOMATION LIMITED 2022.pdf</td>\n",
       "      <td>52</td>\n",
       "      <td>principal activity of the Company is investmen...</td>\n",
       "      <td>The principal activity of the Company is inves...</td>\n",
       "      <td>[-0.07500034, -0.021864938, -0.04694008, 0.070...</td>\n",
       "      <td>1190</td>\n",
       "      <td>This Sub-class includes the growing of other c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ALLIANCE HEALTHCARE GROUP LIMITED 2023.pdf</td>\n",
       "      <td>82</td>\n",
       "      <td>principal activities of the company is that of...</td>\n",
       "      <td>The principal activities of the company are in...</td>\n",
       "      <td>[-0.06722844, -0.008623031, -0.03112161, -0.01...</td>\n",
       "      <td>1190</td>\n",
       "      <td>This Sub-class includes the growing of other c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ANNAIK LIMITED 2022.pdf</td>\n",
       "      <td>71</td>\n",
       "      <td>principal activity of the Company is that of i...</td>\n",
       "      <td>The principal activity of the Company is that ...</td>\n",
       "      <td>[-0.029021166, -0.020046683, 0.020063434, -0.0...</td>\n",
       "      <td>1190</td>\n",
       "      <td>This Sub-class includes the growing of other c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AP OIL INTERNATIONAL LIMITED 2022.pdf</td>\n",
       "      <td>61</td>\n",
       "      <td>The  The Company is an investment holding comp...</td>\n",
       "      <td>The Company is an investment holding company. ...</td>\n",
       "      <td>[-0.05421597, -0.0050037336, 0.006176454, 0.00...</td>\n",
       "      <td>1130</td>\n",
       "      <td>This Sub-class includes growing of fruits such...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       PDF Name  Page Number  \\\n",
       "0                 ABR HOLDINGS LIMITED 2022.pdf           74   \n",
       "1      ABUNDANCE INTERNATIONAL LIMITED 2022.pdf           56   \n",
       "2                    ABUNDANTE LIMITED 2023.pdf           48   \n",
       "3                       ACCRELIST LTD. 2023.pdf           55   \n",
       "4             ACESIAN PARTNERS LIMITED 2022.pdf           54   \n",
       "5                            ACMA LTD. 2022.pdf           48   \n",
       "6  ADVANCED SYSTEMS AUTOMATION LIMITED 2022.pdf           52   \n",
       "7    ALLIANCE HEALTHCARE GROUP LIMITED 2023.pdf           82   \n",
       "8                       ANNAIK LIMITED 2022.pdf           71   \n",
       "9         AP OIL INTERNATIONAL LIMITED 2022.pdf           61   \n",
       "\n",
       "                                  Notes Page Content  \\\n",
       "0  principal activities of the Company are the ma...   \n",
       "1  principal activities of the Company are those ...   \n",
       "2  principal activities of the Company are those ...   \n",
       "3  principal activities of the Company is investm...   \n",
       "4  principal activities of the Group consist of d...   \n",
       "5  principal activity of the Company is that of i...   \n",
       "6  principal activity of the Company is investmen...   \n",
       "7  principal activities of the company is that of...   \n",
       "8  principal activity of the Company is that of i...   \n",
       "9  The  The Company is an investment holding comp...   \n",
       "\n",
       "                              Summarized_Description  \\\n",
       "0  The principal activities of the Company are th...   \n",
       "1  The principal activities of the Company are th...   \n",
       "2  The Company's ultimate controlling party is Le...   \n",
       "3  The principal activities of the Company are in...   \n",
       "4  The principal activities of the Group consist ...   \n",
       "5  The principal activity of Acma Ltd. is that of...   \n",
       "6  The principal activity of the Company is inves...   \n",
       "7  The principal activities of the company are in...   \n",
       "8  The principal activity of the Company is that ...   \n",
       "9  The Company is an investment holding company. ...   \n",
       "\n",
       "                                          Embeddings  Best_Match_SSIC  \\\n",
       "0  [-0.020132285, -0.10326839, -0.01515015, 0.012...             1120   \n",
       "1  [-0.033344787, -0.049288258, 0.022993648, -0.0...             1190   \n",
       "2  [-0.07526265, -0.040298507, 0.029111238, 0.032...             1111   \n",
       "3  [-0.0043711183, -0.050210413, -0.010950963, -0...             1190   \n",
       "4  [-0.0027161513, 0.0018759626, -0.027635382, -0...             1190   \n",
       "5  [-0.046834115, 0.02470865, -0.029877186, -0.02...             1190   \n",
       "6  [-0.07500034, -0.021864938, -0.04694008, 0.070...             1190   \n",
       "7  [-0.06722844, -0.008623031, -0.03112161, -0.01...             1190   \n",
       "8  [-0.029021166, -0.020046683, 0.020063434, -0.0...             1190   \n",
       "9  [-0.05421597, -0.0050037336, 0.006176454, 0.00...             1130   \n",
       "\n",
       "                               Best_Match_Definition  \n",
       "0  This sub-class includes the cultivation of lea...  \n",
       "1  This Sub-class includes the growing of other c...  \n",
       "2  This sub-class includes the cultivation of lea...  \n",
       "3  This Sub-class includes the growing of other c...  \n",
       "4  This Sub-class includes the growing of other c...  \n",
       "5  This Sub-class includes the growing of other c...  \n",
       "6  This Sub-class includes the growing of other c...  \n",
       "7  This Sub-class includes the growing of other c...  \n",
       "8  This Sub-class includes the growing of other c...  \n",
       "9  This Sub-class includes growing of fruits such...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "#pretained minil,\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Convert the summarized descriptions and SSIC definitions to embeddings\n",
    "test_linkedin=df_linkedIn.head(10)\n",
    "test_ssicref=SSIC_ref_df.head(10)\n",
    "test_linkedin['Embeddings'] = (test_linkedin.head(10))['Summarized_Description'].apply(lambda x: model.encode(x))\n",
    "test_ssicref['Embeddings'] = test_ssicref['Detailed Definitions'].apply(lambda x: model.encode(x))\n",
    "\n",
    "\n",
    "def find_best_ssic_match(company_embedding, fact_table):\n",
    "    best_match = None\n",
    "    best_similarity = -1\n",
    "    best_definition = None\n",
    "\n",
    "    for _, row in fact_table.iterrows():\n",
    "        similarity = util.pytorch_cos_sim(company_embedding, row['Embeddings'])[0][0].item()\n",
    "        \n",
    "        if similarity > best_similarity:\n",
    "            best_similarity = similarity\n",
    "            best_match = row['SSIC 2020']\n",
    "            best_definition = row['Detailed Definitions']\n",
    "    \n",
    "    return best_match, best_similarity, best_definition\n",
    "\n",
    "# Find the best matching SSIC code and its detailed definition for each company\n",
    "matches = test_linkedin['Embeddings'].apply(lambda x: find_best_ssic_match(x, test_ssicref))\n",
    "\n",
    "# Extract the best match SSIC and detailed definition\n",
    "test_linkedin['Best_Match_SSIC'] = matches.apply(lambda x: x[0])\n",
    "test_linkedin['Best_Match_Definition'] = matches.apply(lambda x: x[2])\n",
    "\n",
    "test_linkedin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 150, but your input_length is only 94. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=47)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: The principal activities of the Company are those of print and paper management related activities and investment holding. The subsidiaries include trading of commodity chemical products, provision of water treatment solutions using microbial and/or chemicals in the People's Republic of China and in investment and trading of securities.\n"
     ]
    }
   ],
   "source": [
    "test_row_index = 1  \n",
    "test_description = test_linkedin.iloc[test_row_index]['Notes Page Content']\n",
    "test_summary = summarizer(test_description, max_length=150, min_length=30, do_sample=False)[0]['summary_text']\n",
    "print(\"Summary:\", test_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6884\\3155042889.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SSIC_ref_df['Embeddings'] = SSIC_ref_df['Detailed Definitions'].apply(lambda x: model.encode(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIC Code: 94110, Similarity: 0.4943753480911255, Definition: This Sub-class includes:\n",
      "•activities of organisations whose members’ interests centre on the development and prosperity of enterprises in a particular line of business or trade, including farming, or on the economic growth and climate of a particular geographical area or political sub-division without regard for the line of business\n",
      "•activities of federations of such associations\n",
      "•activities of chambers of commerce, guilds and similar organisations\n",
      "•dissemination of information, representation before government agencies, public relations and labour negotiations of business and employer organisations\n",
      "SSIC Code: 64201, Similarity: 0.49186697602272034, Definition: This Sub-class includes the activities of bank/financial holding companies, i.e. units that hold the assets (owning controlling-levels of equity) of a group of subsidiary corporations and whose principal activity is owning the group. The holding companies in this Sub-class generally do not provide any other service to the businesses in which the equity is held, i.e. they do not administer or manage other units.\n",
      "SSIC Code: 64202, Similarity: 0.48793506622314453, Definition: This Sub-class includes holding companies (e.g. real estate, construction, production, distribution) that hold the assets (owning controlling-levels of equity) of a group of subsidiary corporations and whose principal activity is owning the group. The holding companies in this Sub-class generally do not administer or manage the other businesses in which the equity is held.\n"
     ]
    }
   ],
   "source": [
    "test_embedding = model.encode(test_summary)\n",
    "SSIC_ref_df['Embeddings'] = SSIC_ref_df['Detailed Definitions'].apply(lambda x: model.encode(x))\n",
    "\n",
    "def find_top_ssic_matches(test_embedding, fact_table_embeddings):\n",
    "    similarities = []\n",
    "\n",
    "    for _, row in fact_table_embeddings.iterrows():\n",
    "        similarity = util.pytorch_cos_sim(test_embedding, row['Embeddings'])[0][0].item()\n",
    "        similarities.append((row['SSIC 2020'], similarity, row['Detailed Definitions']))\n",
    "\n",
    "    topN = sorted(similarities, key=lambda x: x[1], reverse=True)[:3] #n=3\n",
    "    return topN\n",
    "\n",
    "top_matches = find_top_ssic_matches(test_embedding, SSIC_ref_df)\n",
    "\n",
    "for match in top_matches:\n",
    "    print(f\"SSIC Code: {match[0]}, Similarity: {match[1]}, Definition: {match[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSIC Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_summarised=pd.read_excel(\"Summarised_output_new.xlsx\")\n",
    "df_summarised.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "df_summarised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates based on the 'SSIC 2020' column, keeping the first occurrence\n",
    "SSIC_ref_df = SSIC_ref_df.drop_duplicates(subset=['SSIC 2020'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get embeddings for SSIC ref table\n",
    "def get_embeddings(text,tokenizer,model):\n",
    "    inputs = tokenizer(text, return_tensors='pt', max_length=512, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze()\n",
    "\n",
    "SSIC_ref_df['Embeddings'] = SSIC_ref_df['Detailed Definitions'].apply( lambda x: get_embeddings(x,tokenizer,model).numpy())\n",
    "\n",
    "df_for_Summary['original_embedding']=df_for_Summary['Notes Page Content'].apply(lambda x: get_embeddings(x,tokenizer,model).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted SSIC Code: LABEL_62\n"
     ]
    }
   ],
   "source": [
    "#predict SSIC\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import pipeline\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, pipeline\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=87) # num_labels=len(df_prep)\n",
    "\n",
    "# Prediction pipeline\n",
    "predictor = pipeline('text-classification', model=model, tokenizer=tokenizer,framework='pt', device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "# Example company description\n",
    "company_description = \"The consolidated financial statements relate to the Company and its subsidiaries. The Group acquired 100% of the ordinary shares Fu Yu Supply Chain Solutions Pte. Ltd. in prior year. FYSCS is engaged in the business in providing supply chain management services..\"\n",
    "predictions = predictor(company_description)\n",
    "predicted_ssic_code = predictions[0]['label']\n",
    "\n",
    "print(f\"Predicted SSIC Code: {predicted_ssic_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_23540\\1649197315.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_prep['encoded_cat'] = df_prep[lvl_train].astype('category').cat.codes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SSIC 2020</th>\n",
       "      <th>encoded_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1113</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1119</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1120</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>97001</td>\n",
       "      <td>1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>97002</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>99010</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>99020</td>\n",
       "      <td>1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>99090</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1023 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SSIC 2020  encoded_cat\n",
       "0          1111            0\n",
       "1          1112            1\n",
       "2          1113            2\n",
       "3          1119            3\n",
       "4          1120            4\n",
       "...         ...          ...\n",
       "1018      97001         1018\n",
       "1019      97002         1019\n",
       "1020      99010         1020\n",
       "1021      99020         1021\n",
       "1022      99090         1022\n",
       "\n",
       "[1023 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lvl_train = 'SSIC 2020'\n",
    "lvl_train_title = lvl_train + \" Title\"\n",
    "###############################################################################################################################################\n",
    "\n",
    "df_prep = SSIC_ref_df[[lvl_train, lvl_train_title, 'Detailed Definitions']]\n",
    "df_prep['encoded_cat'] = df_prep[lvl_train].astype('category').cat.codes\n",
    "# df_prep['encoded_cat'] = df_prep[lvl_train] + ' ' + df_prep[lvl_train_title]\n",
    "# df_prep['encoded_cat'] = df_prep['encoded_cat'].astype('category')\n",
    "\n",
    "data_texts = df_prep['Detailed Definitions'].to_list() # Features (not tokenized yet)\n",
    "data_labels = df_prep['encoded_cat'].to_list() # Labels\n",
    "\n",
    "df_prep = df_prep[[lvl_train, 'encoded_cat']].drop_duplicates()\n",
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23540\\1603610569.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Epoch {epoch+1}, Loss: {loss.item()}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m             )\n\u001b[1;32m--> 522\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m         )\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# Assuming data_texts and data_labels are defined\n",
    "train_texts = data_texts\n",
    "train_labels = data_labels\n",
    "val_texts = data_texts\n",
    "val_labels = data_labels\n",
    "\n",
    "# Keep some data for inference (testing)\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(train_texts, train_labels, test_size=0.01, random_state=0, shuffle=True)\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding=True)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = TextDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = TextDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=1023)\n",
    "model.train()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, eps=1e-08)\n",
    "\n",
    "for epoch in range(3):  # Assuming 3 epochs\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
